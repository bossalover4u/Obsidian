# Как Facebook фильтрует контент

Facebook и так постоянно скрывает от нас 80% всего написанного друзьями. Два года назад администраторы соцсети на официальной странице «Facebook для бизнеса» рассказали с цифрами, как это работает: всякий раз, когда среднестатистический пользователь заходит в соцсеть, его поджидают 1500 новых непрочитанных постов, в которых он рискует утонуть с головой. Умный алгоритм, зная наши предпочтения, выбирает из них 300 — только они отобразятся в ленте, остальные 1200 будут забракованы. Когда алгоритму предстоит тяжелый выбор — показать нам свежее фото со страницы лучшего друга, где помечены вы и ваша девушка, или пост про футбол у человека, с которым вы случайно познакомились в долгой очереди к стоматологу и с тех пор не общались, — алгоритм обычно знает, как поступить.

Команду Facebook интересовало, как зачистка ленты отразится на поведении подопытных. Для этого ученые снова воспользовались своим излюбленным методом — подсчетом слов. Оказалось, что те, у кого из френдленты поудаляли «позитивные» записи, сами начали писать более мрачные тексты: частота соответствующих слов- маркеров выросла настолько, что с вероятностью 99,3% это нельзя было назвать случайным совпадением. В научной статье с описанием результатов, которую два года спустя, в марте 2014-го, опубликовал авторитетный журнал Proceedings of the National Academy of Sciences («Вестник Национальной академии наук США»), авторы говорят про «массовое заражение эмоциями через соцсети»

...ваши друзья в Facebook — довольно специальная выборка социально успешных людей, а никакие не «все», которых мы то и дело упоминаем. Социологи сказали бы, что выборка нерепрезентативна — и не только в том смысле, что убеждения вашего круга общения отличаются от убеждений страны в целом.

Нам важно знать, что «все» думают и говорят по тому или иному поводу, — и лента Facebook создает иллюзию общественного мнения. «Вся Москва обсуждает колонку Олега Кашина». «Всем ясно, что заявление про террористов — идиотская фальшивка». «Все уехали на Новый год в Индию». Обычно это неправда не только по отношению к обществу в целом, но и применительно к людям одного с вами возраста, положения и убеждений. Те, у кого друзей за тысячу, имеют понятные причины больше переживать по поводу права свободно высказываться, чем те, у кого друзей пятьдесят. Благодаря «парадоксу дружбы» среди наших друзей больше первых, чем вторых (и эти первые слышней), — поэтому нам и кажется, что ценность свободы слова понятна и самоочевидна всем, кроме редких маргиналов. А результаты опроса ВЦИОМ про 58% сторонников цензуры в интернете представляются внезапными и даже невозможными.

И соцсети, и поисковики активно помогают нам изолировать себя от непохожих мнений — вроде мнений сторонников цензуры. Три года назад вышла книга американского левого активиста Эли Паризера «Пузырь фильтров» с подзаголовком «Как новый персонализированный интернет влияет на то, что мы читаем и что мы думаем». Когда сосед из квартиры сверху и вы одновременно заходите на главную страницу Google, поисковая выдача по одному и тому же запросу у вас будет разной — начиная с 2009 года Google подстраивает ее под ваши интересы. Например, по слову «Форд» поисковик выдаст вам биографию Генри Форда, а соседу — страницу салона, где торгуют автомобилями. То же самое, утверждает Паризер, касается и проблемных тем. Если вы параноидально боитесь ГМО, то на первой странице поисковой выдачи будут преобладать сайты про вред «еды Франкенштейна», а если вы биотехнолог — то ресурсы с более рациональным взглядом на вещи.

[…] Тут же выяснилось, что у либералов свои новости, а у консерваторов — свои. Вместо того чтобы обсуждать одни и те же статьи с разных позиций, люди противоположных политических убеждений делают акцент на разных событиях и возмущаются каждый своими несправедливостями. Условно говоря (если распространить выводы на российский сегмент Facebook), одни больше пишут про «события мая на Болотной», другие — про «жертв мая в Одессе». Само собой, источники цитируются тоже разные: если вы увидели ссылку на FoxNews.com, с вероятностью 80% можно утверждать, что ею поделился консерватор. А на HuffingtonPost.com, наоборот, в 65% случаев ссылаются либералы. И оба потока новостей, «консервативный» и «либеральный», в соцсетях активно фильтруются.

Исследователи Эйтан Бакши, Соломон Мессинг и Лада Адамич проанализировавшие ленты 10,1 млн пользователей из США, подчеркивают, что в каскаде идеологических фильтров роль алгоритмов не такая уж большая. За невозможностью узнать чужую точку зрения стоит, прежде всего, наша свободная воля. Что может быть естественнее желания читать единомышленников и нежелания лайкать то, что расходится с устоявшимися взглядами? Получается парадокс: если предоставить пользователям полную свободу доступа к информации — мы приложим максимум усилий, чтобы себя дезинформировать.

Социальные сети, казалось бы, полная противоположность ТВ — что смотреть и что читать, выбираем вроде бы мы сами, а не какие-то сценаристы и продюсеры новостных программ. Единственные злые парни в этой ситуации — наши собственные когнитивные ошибки, от стремления идеализировать жизнь других людей до нетерпимости к чужим мнениям. Коварные манипуляторы из числа штатных сотрудников Google, Twitter или Facebook в этом не виноваты — они просто предоставили нам возможность жить и действовать так, как мы давно хотели. Просто на практике это оборачивается непробиваемым пузырем заблуждений.

https://goo.gl/QbaaVn

#Факти
[[Влияние сетевых технологий на выборы]]
[[Маршалл Маклюэн о новых технологиях медиа]]
[[Перша та друга сторінки пошуку Google]]
[[Эрих Фромм о медиаманипуляциях]]
[[Подборка промптов для SEO для оптимизации вашего текста]]
[[Промпты для ведения блога]]
[[Промпты для контента]]
[[Які статті любить Google]]
[[SEO-оптимизированный текст в ChatGPT]]


